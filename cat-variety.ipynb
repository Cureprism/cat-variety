{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNTMx684NApPl/DHLqvK5o9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# ColabをDrive内で使う\n","from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive\n","\n","# 作業フォルダを作る（初回のみ）\n","# !mkdir -p cat-variety\n","# %cd cat-variety\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Be8b9t-fxpkx","executionInfo":{"status":"ok","timestamp":1760447529205,"user_tz":-540,"elapsed":22552,"user":{"displayName":"fumio takaki","userId":"09198796640530461317"}},"outputId":"fe37fa31-e4aa-4b85-e8b7-f7dbaafd3975"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":839},"id":"XQJt9DNee1SZ","executionInfo":{"status":"ok","timestamp":1760349504246,"user_tz":-540,"elapsed":1314791,"user":{"displayName":"fumio takaki","userId":"09198796640530461317"}},"outputId":"9fb708da-e389-46ba-e1ca-f014dd5fd064"},"outputs":[{"output_type":"stream","name":"stdout","text":["Python version: 3.12.11 (main, Jun  4 2025, 08:56:18) [GCC 11.4.0]\n","Platform: Linux-6.6.97+-x86_64-with-glibc2.35\n","Mon Oct 13 09:36:30 2025       \n","+-----------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n","|-----------------------------------------+------------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                        |               MIG M. |\n","|=========================================+========================+======================|\n","|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n","| N/A   35C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n","|                                         |                        |                  N/A |\n","+-----------------------------------------+------------------------+----------------------+\n","                                                                                         \n","+-----------------------------------------------------------------------------------------+\n","| Processes:                                                                              |\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n","|        ID   ID                                                               Usage      |\n","|=========================================================================================|\n","|  No running processes found                                                             |\n","+-----------------------------------------------------------------------------------------+\n","Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (1.7.4.5)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle) (6.2.0)\n","Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2025.10.5)\n","Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.4.3)\n","Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.10)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle) (5.29.5)\n","Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.9.0.post0)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle) (8.0.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.32.4)\n","Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle) (75.2.0)\n","Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.17.0)\n","Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle) (4.67.1)\n","Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.5.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle) (0.5.1)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-a915b42a-a0c6-4119-954d-ea62b581ec7b\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-a915b42a-a0c6-4119-954d-ea62b581ec7b\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving kaggle.json to kaggle.json\n","Dataset URL: https://www.kaggle.com/datasets/ma7555/cat-breeds-dataset\n","License(s): DbCL-1.0\n","Downloading cat-breeds-dataset.zip to /content/drive/MyDrive/cat-variety\n"," 99% 1.92G/1.93G [00:12<00:00, 200MB/s]\n","100% 1.93G/1.93G [00:12<00:00, 168MB/s]\n"]}],"source":["# # Kaggleからデータセットをダウンロード\n","# # Google Colabの基本確認\n","# import sys, platform\n","# print(\"Python version:\", sys.version)\n","# print(\"Platform:\", platform.platform())\n","\n","# # GPU確認\n","# !nvidia-smi\n","\n","# # Kaggle APIのインストール\n","# !pip install kaggle\n","\n","# from google.colab import files\n","# files.upload()  # kaggle.jsonをアップロード\n","\n","# # 認証設定\n","# !mkdir -p ~/.kaggle\n","# !mv kaggle.json ~/.kaggle/\n","# !chmod 600 ~/.kaggle/kaggle.json\n","\n","# # データセットをColabにダウンロード\n","# !kaggle datasets download -d ma7555/cat-breeds-dataset --unzip\n"]},{"cell_type":"code","source":["# 必要な画像のみをDriveに保存\n","import os\n","import shutil\n","\n","# 元データの場所（Kaggleから展開したフォルダ）\n","src_dir = \"/content/drive/MyDrive/cat-variety/images/images\"\n","\n","# 保存先（Google Drive）\n","dst_dir = \"/content/drive/MyDrive/cat-variety/data/train\"\n","os.makedirs(dst_dir, exist_ok=True)\n","\n","# 抽出する7品種\n","selected_breeds = [\n","    \"Scottish Fold\",\n","    \"American Shorthair\",\n","    \"Russian Blue\",\n","    \"Siamese\",\n","    \"Persian\",\n","    \"Maine Coon\",\n","    \"Norwegian Forest Cat\"\n","]\n","\n","# コピー処理\n","for breed in selected_breeds:\n","    src_path = os.path.join(src_dir, breed)\n","    dst_path = os.path.join(dst_dir, breed)\n","    if os.path.exists(src_path):\n","        shutil.copytree(src_path, dst_path)\n","        print(f\"✅ {breed} をコピーしました。\")\n","    else:\n","        print(f\"⚠️ {breed} が見つかりません。\")\n","\n","print(\"\\n整理完了。Drive内フォルダ:\")\n","print(os.listdir(dst_dir))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UJS6ELAUkd_Q","executionInfo":{"status":"ok","timestamp":1760449536583,"user_tz":-540,"elapsed":189989,"user":{"displayName":"fumio takaki","userId":"09198796640530461317"}},"outputId":"10f357a1-f97d-472e-c2b7-ecd924ba363c"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Scottish Fold をコピーしました。\n","✅ Russian Blue をコピーしました。\n","✅ Siamese をコピーしました。\n","✅ Persian をコピーしました。\n","✅ Maine Coon をコピーしました。\n","✅ Norwegian Forest Cat をコピーしました。\n","\n","整理完了。Drive内フォルダ:\n","['American Shorthair', 'Scottish Fold', 'Russian Blue', 'Siamese', 'Persian', 'Maine Coon', 'Norwegian Forest Cat']\n"]}]},{"cell_type":"code","source":["# 基本ライブラリ\n","import torch\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms\n","\n","# GPU確認\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)\n","\n","# 画像前処理\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),   # 画像サイズを統一\n","    transforms.ToTensor(),           # Tensor化\n","    transforms.Normalize(            # 標準化\n","        mean=[0.485, 0.456, 0.406],\n","        std=[0.229, 0.224, 0.225]\n","    )\n","])\n","\n","# データセット読み込み\n","train_dir = \"/content/drive/MyDrive/cat-variety/data/train\"\n","train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n","\n","# ローダー作成\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","\n","print(f\"画像枚数: {len(train_dataset)}\")\n","print(f\"クラス一覧: {train_dataset.classes}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RAFDpvTzkk67","executionInfo":{"status":"ok","timestamp":1760449606991,"user_tz":-540,"elapsed":754,"user":{"displayName":"fumio takaki","userId":"09198796640530461317"}},"outputId":"36a8783b-2e00-4322-d11c-3188d07edb00"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n","画像枚数: 16449\n","クラス一覧: ['American Shorthair', 'Maine Coon', 'Norwegian Forest Cat', 'Persian', 'Russian Blue', 'Scottish Fold', 'Siamese']\n"]}]},{"cell_type":"code","source":["# モデル定義\n","\n","import torch.nn as nn\n","from torchvision import models\n","\n","# 事前学習済みResNet18をロード\n","model = models.resnet18(pretrained=True)\n","\n","# 出力層を品種数に合わせて置き換え\n","num_classes = len(train_dataset.classes)\n","model.fc = nn.Linear(model.fc.in_features, num_classes)\n","\n","# GPU対応\n","model = model.to(device)\n","\n","print(model)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ACHJ_UNktL6-","executionInfo":{"status":"ok","timestamp":1760450131129,"user_tz":-540,"elapsed":357,"user":{"displayName":"fumio takaki","userId":"09198796640530461317"}},"outputId":"26dd7659-e45b-47ed-cfff-8a29b56e8fd7"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=7, bias=True)\n",")\n"]}]},{"cell_type":"code","source":["# 損失関数と最適化アルゴリズム」の設定\n","import torch.optim as optim\n","\n","# 損失関数（分類問題なのでクロスエントロピー）\n","criterion = nn.CrossEntropyLoss()\n","\n","# 最適化手法（SGDより安定するAdamを使用/Adam：各パラメータごとに最適な学習率を自動調整）\n","optimizer = optim.Adam(model.parameters(), lr=0.0001)\n","\n","print(\"損失関数:\", criterion)\n","print(\"最適化手法:\", optimizer)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JV8pWYtCtdhj","executionInfo":{"status":"ok","timestamp":1760450481788,"user_tz":-540,"elapsed":48,"user":{"displayName":"fumio takaki","userId":"09198796640530461317"}},"outputId":"fa499250-e011-4ac2-e17a-d3a0e42e29a8"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["損失関数: CrossEntropyLoss()\n","最適化手法: Adam (\n","Parameter Group 0\n","    amsgrad: False\n","    betas: (0.9, 0.999)\n","    capturable: False\n","    decoupled_weight_decay: False\n","    differentiable: False\n","    eps: 1e-08\n","    foreach: None\n","    fused: None\n","    lr: 0.0001\n","    maximize: False\n","    weight_decay: 0\n",")\n"]}]},{"cell_type":"code","source":["# 学習ループ\n","num_epochs = 1  # 初回は1で確認\n","model.train()\n","\n","for epoch in range(num_epochs):\n","    running_loss = 0.0\n","    for images, labels in train_loader:\n","        images, labels = images.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()           # 勾配リセット\n","        outputs = model(images)         # 推論\n","        loss = criterion(outputs, labels)  # 損失計算\n","        loss.backward()                 # 逆伝播\n","        optimizer.step()                # 重み更新\n","\n","        running_loss += loss.item()\n","\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zw1orMhhCZMv","executionInfo":{"status":"ok","timestamp":1760450860504,"user_tz":-540,"elapsed":156019,"user":{"displayName":"fumio takaki","userId":"09198796640530461317"}},"outputId":"e0c74f1a-82b8-4a24-c569-3157808743ca"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/1], Loss: 0.6534\n"]}]},{"cell_type":"code","source":["# 学習データを訓練用と検証用に分割\n","from torch.utils.data import random_split\n","\n","# 全データを8:2に分割\n","train_size = int(0.8 * len(train_dataset))\n","val_size = len(train_dataset) - train_size\n","\n","train_subset, val_subset = random_split(train_dataset, [train_size, val_size])\n","\n","# 検証用データローダー\n","val_loader = DataLoader(val_subset, batch_size=32, shuffle=False)\n","\n","print(f\"train: {len(train_subset)}, val: {len(val_subset)}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PhMTjWQ0ECH4","executionInfo":{"status":"ok","timestamp":1760451142339,"user_tz":-540,"elapsed":45,"user":{"displayName":"fumio takaki","userId":"09198796640530461317"}},"outputId":"ffcc4392-aa18-4013-dbc1-086ba05edc1e"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["train: 13159, val: 3290\n"]}]},{"cell_type":"code","source":["# 検証データでの精度計算\n","model.eval()  # 評価モード\n","correct = 0\n","total = 0\n","\n","with torch.no_grad():  # 勾配計算オフ\n","    for images, labels in val_loader:\n","        images, labels = images.to(device), labels.to(device)\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","accuracy = 100 * correct / total\n","print(f\"検証データ精度: {accuracy:.2f}%\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8srzqzYhEVBg","executionInfo":{"status":"ok","timestamp":1760451252497,"user_tz":-540,"elapsed":26311,"user":{"displayName":"fumio takaki","userId":"09198796640530461317"}},"outputId":"8d2df275-1434-4823-cb0e-8225599bf278"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["検証データ精度: 90.70%\n"]}]},{"cell_type":"code","source":["# エポックを増やして精度推移を見る\n","num_epochs = 5  # 試しに5回\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss = 0.0\n","    for images, labels in train_loader:\n","        images, labels = images.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item()\n","\n","    # 検証\n","    model.eval()\n","    correct = total = 0\n","    with torch.no_grad():\n","        for images, labels in val_loader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            _, predicted = torch.max(outputs, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    acc = 100 * correct / total\n","    print(f\"Epoch [{epoch+1}/{num_epochs}] Loss: {running_loss/len(train_loader):.4f}  Val Acc: {acc:.2f}%\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s2Ux7Cp1FXeh","executionInfo":{"status":"ok","timestamp":1760452367995,"user_tz":-540,"elapsed":889221,"user":{"displayName":"fumio takaki","userId":"09198796640530461317"}},"outputId":"144a2fd1-f01e-4088-f3de-4cbe773b531c"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/5] Loss: 0.3074  Val Acc: 96.60%\n","Epoch [2/5] Loss: 0.1256  Val Acc: 99.03%\n","Epoch [3/5] Loss: 0.0641  Val Acc: 97.42%\n","Epoch [4/5] Loss: 0.0545  Val Acc: 99.18%\n","Epoch [5/5] Loss: 0.0623  Val Acc: 98.91%\n"]}]},{"cell_type":"code","source":["# 学習済みモデルの保存\n","# Driveへの保存パス\n","save_path = \"/content/drive/MyDrive/cat-variety/model/cat_model.pth\"\n","\n","# モデル保存\n","torch.save(model.state_dict(), save_path)\n","print(f\"モデルを保存しました: {save_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZBqg_kWiKCOv","executionInfo":{"status":"ok","timestamp":1760452794524,"user_tz":-540,"elapsed":131,"user":{"displayName":"fumio takaki","userId":"09198796640530461317"}},"outputId":"1e75081b-160d-47e1-da1a-7690eeba74ca"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["モデルを保存しました: /content/drive/MyDrive/cat-variety/model/cat_model.pth\n"]}]}]}