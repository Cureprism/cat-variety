{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMIaL9YUzQzCDgTYhUxTPsD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## データセットについて\n","本モデルの学習には、以下の Kaggle データセットを使用しました。\n","\n","- **Cat Breeds Dataset**  \n","  https://www.kaggle.com/datasets/ma7555/cat-breeds-dataset\n","\n","※ データセットは学習前にダウンロードし、必要な品種のみを  \n","　`data/raw/` → `data/train/` のディレクトリ構成へ整理しています。  \n","　この Notebook では、学習プロセスを示すために必要なコードのみ掲載しています。\n"],"metadata":{"id":"rPwQhqxe7V87"}},{"cell_type":"markdown","source":["## データ準備\n","Kaggle から取得した元データを `data/raw/` に配置し、  \n","学習で使用する 7 品種を `data/train/` にコピーします。\n"],"metadata":{"id":"MNoas6mnDfAh"}},{"cell_type":"code","source":["import os\n","import shutil\n","\n","src_dir = \"data/raw\"     # 元データ（手動配置）\n","dst_dir = \"data/train\"   # 学習に使うフォルダ\n","os.makedirs(dst_dir, exist_ok=True)\n","\n","selected_breeds = [\n","    \"Scottish Fold\",\n","    \"American Shorthair\",\n","    \"Russian Blue\",\n","    \"Siamese\",\n","    \"Persian\",\n","    \"Maine Coon\",\n","    \"Norwegian Forest Cat\"\n","]\n","\n","for breed in selected_breeds:\n","    src_path = os.path.join(src_dir, breed)\n","    dst_path = os.path.join(dst_dir, breed)\n","    if os.path.exists(src_path):\n","        shutil.copytree(src_path, dst_path, dirs_exist_ok=True)\n","        print(f\"{breed} をコピーしました\")\n","    else:\n","        print(f\"{breed} は元データに存在しません\")\n"],"metadata":{"id":"UJS6ELAUkd_Q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## データ読み込み\n","`data/train/` から画像データを読み込み、前処理を行います。"],"metadata":{"id":"cun4oxrrDwrN"}},{"cell_type":"code","source":["import torch\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)\n","\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(\n","        mean=[0.485, 0.456, 0.406],\n","        std=[0.229, 0.224, 0.225]\n","    )\n","])\n","\n","train_dataset = datasets.ImageFolder(root=\"data/train\", transform=transform)\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","\n","print(f\"画像枚数: {len(train_dataset)}\")\n","print(f\"クラス一覧: {train_dataset.classes}\")"],"metadata":{"id":"RAFDpvTzkk67"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## モデル定義\n","ResNet18 の最終層を、分類対象の品種数に合わせて置き換えます。"],"metadata":{"id":"w3eMjNKuD-G5"}},{"cell_type":"code","source":["import torch.nn as nn\n","from torchvision import models\n","\n","model = models.resnet18(pretrained=True)\n","\n","num_classes = len(train_dataset.classes)\n","model.fc = nn.Linear(model.fc.in_features, num_classes)\n","model = model.to(device)\n","\n","print(model)"],"metadata":{"id":"ACHJ_UNktL6-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 損失関数と最適化手法\n","クロスエントロピー損失と Adam を使用します。"],"metadata":{"id":"n1vYJcSMEGkC"}},{"cell_type":"code","source":["import torch.optim as optim\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.0001)\n","\n","print(\"損失関数:\", criterion)\n","print(\"最適化手法:\", optimizer)"],"metadata":{"id":"JV8pWYtCtdhj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 学習（1 Epoch）\n","まずは 1 エポックだけ実行して学習が動作するか確認します。"],"metadata":{"id":"2rbg2665ES7i"}},{"cell_type":"code","source":["num_epochs = 1\n","model.train()\n","\n","for epoch in range(num_epochs):\n","    running_loss = 0.0\n","    for images, labels in train_loader:\n","        images, labels = images.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()           # 勾配リセット\n","        outputs = model(images)         # 推論\n","        loss = criterion(outputs, labels)  # 損失計算\n","        loss.backward()                 # 逆伝播\n","        optimizer.step()                # 重み更新\n","\n","        running_loss += loss.item()\n","\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n"],"metadata":{"id":"zw1orMhhCZMv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 検証データの分割と精度確認\n","学習データを 8:2 に分割し、検証精度を測定します。"],"metadata":{"id":"3Kv6CKFiEiRg"}},{"cell_type":"code","source":["from torch.utils.data import random_split\n","\n","train_size = int(0.8 * len(train_dataset))\n","val_size = len(train_dataset) - train_size\n","\n","train_subset, val_subset = random_split(train_dataset, [train_size, val_size])\n","val_loader = DataLoader(val_subset, batch_size=32, shuffle=False)\n","\n","model.eval()\n","correct = total = 0\n","\n","with torch.no_grad():\n","    for images, labels in val_loader:\n","        images, labels = images.to(device), labels.to(device)\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","accuracy = 100 * correct / total\n","print(f\"検証データ精度: {accuracy:.2f}%\")\n"],"metadata":{"id":"PhMTjWQ0ECH4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 追加学習（5 Epoch）\n","学習を続け、損失と精度の推移を確認します。"],"metadata":{"id":"wFpP4ga8E2AP"}},{"cell_type":"code","source":["# エポックを増やして精度推移を見る\n","num_epochs = 5\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss = 0.0\n","    for images, labels in train_loader:\n","        images, labels = images.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item()\n","\n","    # 検証\n","    model.eval()\n","    correct = total = 0\n","    with torch.no_grad():\n","        for images, labels in val_loader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            _, predicted = torch.max(outputs, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    acc = 100 * correct / total\n","    print(f\"Epoch [{epoch+1}/{num_epochs}] Loss: {running_loss/len(train_loader):.4f}  Val Acc: {acc:.2f}%\")\n"],"metadata":{"id":"s2Ux7Cp1FXeh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## モデル保存\n","学習済みモデル（state_dict）を `model/cat_model.pth` に保存します。"],"metadata":{"id":"eKQzlYwKFBfb"}},{"cell_type":"code","source":["save_path = \"model/cat_model.pth\"\n","os.makedirs(\"model\", exist_ok=True)\n","\n","torch.save(model.state_dict(), save_path)\n","print(f\"モデルを保存しました: {save_path}\")"],"metadata":{"id":"ZBqg_kWiKCOv"},"execution_count":null,"outputs":[]}]}